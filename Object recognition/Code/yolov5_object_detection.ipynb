{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/ultralytics/yolov5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd yolov5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import IProgress\n",
    "from ipywidgets import IntProgress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.get_arch_list() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('All set. Using PyTorch version %s with %s' % (torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the yolov5 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python train.py --img 640 --batch 16 --epochs 300 --data dataset.yaml --weights yolov5s.pt --cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Progress in Google collab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation in Google collab\n",
    "\n",
    "Image(filename='runs/train/exp2/val_batch0_labels.jpg', width=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python detect.py --weights runs/train/exp/weights/best.pt --img 640 --conf 0.25 --source runs/train/exp/weights/test/images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert weights to fp16 TFLite model\n",
    "\n",
    "!python export.py --weights runs/train/exp/weights/best.pt --include tflite --img 640 --data data/datas.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert weights to int8 TFLite model\n",
    "\n",
    "!python export.py --weights runs/train/exp2/weights/best.pt --include tflite --int8 --img 640 --data data/datas.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python detect.py --weights runs\\train\\exp\\weights\\best-fp16-metadata.tflite --img 640 --conf 0.25 --source runs/train/exp/weights/test/images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#After running the above command, you will have best-fp16.tflite in runs\\train\\exp2\\weights folder\n",
    "\n",
    "# Lets run the created tflite model.\n",
    "\n",
    "!python detect.py --weights runs\\train\\exp\\weights\\best-fp16.tflite --img 640 --conf 0.25 --source runs/train/exp/weights/test/images --data data/datas.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd yolov5-tflite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python metadata_writer_v1.py --model_file best-fp16.tflite --label_file labels.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Quantization \n",
    "\n",
    "#dynamic\n",
    "saved_model_dir = \"runs/train/exp/weights/best_saved_model\"\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "tflite_quant_model = converter.convert()\n",
    "open(\"converted_model.tflite\", \"wb\").write(tflite_quant_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#integer with float fallback\n",
    "\n",
    "def representative_dataset():\n",
    "    for _ in range(100):\n",
    "      data = np.random.rand(1, 640, 640, 3)\n",
    "      yield [data.astype(np.float32)]\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_dataset\n",
    "tflite_quant_model = converter.convert()\n",
    "open(\"best-fp16 Integer float fallback quantization.tflite\", \"wb\").write(tflite_quant_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Integer float fallback quantization\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "train_images = \"runs/train/exp/weights/train/images\"\n",
    "\n",
    "def representative_data_gen():\n",
    "    # Assuming you are loading image files from the specified directory\n",
    "    image_files = tf.data.Dataset.list_files(train_images + '/*.jpg')  # Update file extension if needed\n",
    "    for img_path in image_files.take(100):  # Take 100 images for representative dataset\n",
    "        img = tf.io.read_file(img_path)\n",
    "        img = tf.image.decode_jpeg(img, channels=3)  # Assuming RGB images\n",
    "        img = tf.image.resize(img, [640, 640])  # Resize if needed\n",
    "        img = tf.expand_dims(img, 0)  # Add batch dimension\n",
    "        img = img / 255.0  # Normalize to [0, 1]\n",
    "        yield [img]\n",
    "\n",
    "# Assuming saved_model_dir is the directory where your Keras model is saved\n",
    "saved_model_dir = \"runs/train/exp/weights/best_saved_model\"\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_data_gen\n",
    "\n",
    "tflite_model_quant = converter.convert()\n",
    "open(\"best-fp16 Integer float fallback quantization 2.tflite\", \"wb\").write(tflite_model_quant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Float 16\n",
    "\n",
    "import tensorflow as tf\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.target_spec.supported_types = [tf.float16]\n",
    "tflite_quant_model = converter.convert()\n",
    "\n",
    "open(\"best-fp16 Integer float16.tflite\", \"wb\").write(tflite_model_quant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python detect.py --weights runs\\train\\exp\\weights\\best-fp16-Dynamic-range-quantization.tflite --img 640 --conf 0.25 --source runs/train/exp/weights/test/images --data data/datas.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python detect.py --weights runs\\train\\exp\\weights\\best-fp16-Integer-float-fallback-quantization-1-random-dataset.tflite --img 640 --conf 0.25 --source runs/train/exp/weights/test/images --data data/datas.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python detect.py --weights runs\\train\\exp\\weights\\best-fp16-Integer-float-fallback-quantization-2-train-dataset.tflite --img 640 --conf 0.25 --source runs/train/exp/weights/test/images --data data/datas.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python detect.py --weights runs\\train\\exp\\weights\\best-fp16-float16.tflite --img 640 --conf 0.25 --source runs/train/exp/weights/test/images --data data/datas.yaml"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
